# 데이터 분석 관통 프로젝트
## 1. 관통 프로젝트 안내
### 목표
- 레포지토리 이름 : 04_05_PJT

- 공공데이터를 활용하여 데이터를 수집하고, 전처리 과정을 거쳐 탐색적 데이터 분석(EDA)을 수행하는 것을 목표로 함
- 공공데이터 포털(Open API) 및 웹 크롤링을 통해 데이터를 확보하고, pandas와 matplotlib을 사용하여 데이터를 정리, 분석, 시각화함.
- 데이터의 구조와 분포를 파악하고 변수 간 관계를 탐색하여 유의미한 패터능ㄹ 인사이트를 도출하는 데 중점을 둠
---
- 공공데이터(Open API, 크롤링)를 직접 불러오며 데이터 수집 능력 강화
- 결측치 처리, 자료형 변환, 이상치 제거 등 데이터 전처리 경험 축적
- pandas와 matplotlib을 활용하여 기초 통계 및 시각화 역량 강화
- 히스토그램, 막대그래프, 산점도, 라인그래프 등을 통해 데이터 패턴, 특성 분석
- 분석 과정에서 발견한 문제와 패턴을 바탕으로 실무적, 사회적 가치 있는 인사이트 도출

### 준비사항
#### 사용 데이터
- 공공 데이터 포털의 공개 API를 통해 수집한 데이터

#### 개발언어 / 프로그램
- Python : 주 개발 언어
- Pandas : 데이터 불러오기, 정제 및 전처리
- Matplotlib, Seaborn : 데이터 시가고하
- (선택)Ploty : 추가 시각화 도구

### 구현 방법
#### 데이터 수집
- 공공데이터 포털(Open API)를 통해 데이터 수집
- CSV 파일로 저장하여 분석 환경(Python)에서 불러오기

#### 데이터 전처리
- Pandas를 활용하여 결측치 이상치 처리
- 자료형 변환(숫자형, 날짜형)
- 필요 시 파생 변수 생성 ( 예: 날짜 -> 연, 월, 요일 )

#### 탐색적 데이터 분석
- 기초 통계 확인
- 히스토그램, 막대그래프, 박스플롯, 산점도 등을 이용한 데이터 분포, 관계 분석
- 결측치 비율, 변수 간 상관관계 확인
- matplotlib으로 주요 변수의 패턴과 특징 시각화
- 그래프마다 한 줄 해석 작성 -> 최종 분석 보고서 작성

### 요구사항
#### 기본 기능
- Open API 또는 크롤링을 통해 데이터 확보
- Selenium을 활용하여 웹에서 자동 수집
- CSV 파일 형태로 저장 후 분석 환경(Python)에서 불러오기

#### 데이터 전처리
- Pandas를 활용한 결측값 및 이상치 처리
- 텍스트 데이터 정제(토큰화, 정규화, 불용어 제거 등)
- 날짜 - 시간 데이터 변환 및 파생 변수 생성
- 범주형 변수 인코딩, 수치형 데이터 스케일링

#### 시각화 및 탐색적 데이터 분석(EDA)
- 기초 통계량 확인(평균, 분산, 분포, 결측치 현황 등)
- 변수 간 관계 파악(상관계수, 히트맵, 산점도, 박스플롯 등)
- 데이터 패턴, 이상치, 분포 특성 확인
- 주요 특징(feature) 간 상관성 분석 및 시각화

### 산출물
- 데이터 수집 및 전처리에 대한 소스코드와 분석에 대한 내용을 ipynb에 포함하여 Repository에 업로드
- 해당 데이터를 기반으로 이후 머신러닝 PJT를 진행할 것이므로 해당 내용을 고려해서 구상할 것
